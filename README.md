# DataCo Smart Supply Chain Analysis

A comprehensive, multi-level data analytics project analyzing DataCo Global's supply chain operations. This project demonstrates progressive data analytics skills â€” from exploratory analysis to interactive dashboards to predictive machine learning models.

## ğŸ“Š Dataset

**Source:** [DataCo Smart Supply Chain for Big Data Analysis](https://www.kaggle.com/datasets/shashwatwork/dataco-smart-supply-chain-for-big-data-analysis)

The dataset contains **180,000+ order records** with **50+ features** from DataCo Global, covering:
- Customer orders across multiple countries
- Product categories (Clothing, Sports, Electronics)
- Shipping modes and delivery performance
- Financial data (sales, profit, discounts)
- Fraud indicators

---

## ğŸ—‚ï¸ Project Structure

```
dataco-supply-chain-analysis/
â”‚
â”œâ”€â”€ README.md                          # Project overview (you are here)
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Files to exclude from git
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                           # Original dataset (not tracked in git)
â”‚   â””â”€â”€ processed/                     # Cleaned & transformed data
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_data_cleaning.ipynb     # Deliverable 1: EDA & Data Cleaning
â”‚   â”œâ”€â”€ 02_sql_kpi_analysis.ipynb      # Deliverable 2: SQL & KPI Analysis
â”‚   â””â”€â”€ 03_predictive_modeling.ipynb   # Deliverable 3: ML & Fraud Detection
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_cleaning.py               # Reusable cleaning functions
â”‚   â”œâ”€â”€ feature_engineering.py         # Feature creation for ML models
â”‚   â””â”€â”€ visualization.py              # Custom plotting functions
â”‚
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ supply_chain_queries.sql       # SQL queries for KPI extraction
â”‚
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ app.py                         # Plotly Dash interactive dashboard
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ (saved model files .pkl)       # Trained model artifacts
â”‚
â””â”€â”€ reports/
    â””â”€â”€ figures/                       # Exported charts and visualizations
```

---

## ğŸš€ Deliverables

### Deliverable 1 â€” Beginner: Exploratory Data Analysis & Data Cleaning
**Notebook:** `notebooks/01_eda_data_cleaning.ipynb`

- Data import, profiling, and quality assessment
- Handling missing values, duplicates, and data type conversions
- Descriptive statistics across key supply chain metrics
- 10+ visualizations covering order trends, delivery performance, regional breakdowns, and profitability
- Key business findings summarized

**Skills:** Python, Pandas, Matplotlib, Seaborn, Data Wrangling

---

### Deliverable 2 â€” Intermediate: Supply Chain KPI Dashboard
**Notebook:** `notebooks/02_sql_kpi_analysis.ipynb` | **Dashboard:** `dashboards/app.py`

- SQL queries extracting core supply chain KPIs (on-time delivery rate, avg shipping delay, revenue by category, customer segmentation)
- Interactive Plotly Dash dashboard with filters for region, product category, and time period
- Written business recommendations backed by data

**Skills:** SQL, SQLite, Plotly Dash, KPI Development, Business Analysis

---

### Deliverable 3 â€” Expert: Predictive Modeling & Fraud Detection
**Notebook:** `notebooks/03_predictive_modeling.ipynb`

- **Late Delivery Prediction** â€” Classification model predicting delivery delays with feature importance analysis
- **Fraud Detection** â€” Identifying fraudulent orders with precision/recall optimization
- Model evaluation: confusion matrices, ROC curves, cross-validation
- Business impact assessment and recommendations

**Skills:** Scikit-learn, XGBoost, Machine Learning, Model Evaluation, Feature Engineering

---

## âš™ï¸ Setup & Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/dataco-supply-chain-analysis.git
cd dataco-supply-chain-analysis

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download the dataset from Kaggle and place in data/raw/
# https://www.kaggle.com/datasets/shashwatwork/dataco-smart-supply-chain-for-big-data-analysis
```

## ğŸ› ï¸ Tech Stack

| Tool | Purpose |
|------|---------|
| Python 3.10+ | Core language |
| Pandas / NumPy | Data manipulation |
| Matplotlib / Seaborn | Static visualizations |
| Plotly / Dash | Interactive dashboard |
| SQLite | SQL-based analysis |
| Scikit-learn | Machine learning |
| XGBoost | Gradient boosting models |
| Jupyter Notebook | Analysis environment |

---

## ğŸ‘¤ Author

**Samuel â€” Data Analyst**
- [LinkedIn](https://www.linkedin.com/in/samuel-manson-endeboh-7a66a4136/)
- [GitHub](https://github.com/abiyes-stack)

---

## ğŸ“œ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
